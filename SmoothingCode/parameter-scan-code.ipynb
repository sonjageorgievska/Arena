{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter scan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used for making parameter scans. It is based on density estimation code version 3. See that file for explanations.\n",
    "### Caution: \n",
    "The code below writes results to file and then reads them back in for analysis and comparison.\n",
    "You cannot do a Run All before setting the file paths right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal, pearsonr\n",
    "import copy\n",
    "from importlib import reload\n",
    "import dens_estimation as de\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# real dataset\n",
    "\n",
    "data = []\n",
    "with open(\"/Users/philip/Documents/PhD/data/ArenaData/arena_fits/2015-07-05.json\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "json_lines = []\n",
    "\n",
    "for line in data:\n",
    "    jsline = json.loads(line)\n",
    "    json_lines.append(jsline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame.from_dict(json_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rebuild dataframe\n",
    "# make dataframe of dicts nested in 'value' column\n",
    "value = pd.DataFrame(list(frame['value']))\n",
    "del frame['value']\n",
    "\n",
    "# make dataframe of dicts nested in 'trackeeHistory' column\n",
    "trackee = pd.DataFrame(list(value['trackeeHistory']))\n",
    "del value['trackeeHistory']\n",
    "\n",
    "chi2PerDof = pd.DataFrame(list(trackee['chi2PerDof']))\n",
    "chi2PerDof.columns = ['chi2PerDof']\n",
    "probChi2 = pd.DataFrame(list(trackee['probChi2']))\n",
    "probChi2.columns = ['probChi2']\n",
    "nMeasurements = pd.DataFrame(list(trackee['nMeasurements']))\n",
    "nMeasurements.columns = ['nMeasurements']\n",
    "localMac = pd.DataFrame(list(trackee['localMac']))\n",
    "localMac.columns = ['localMac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make dataframe with a 'coordinates' column\n",
    "averagecoordinate = pd.DataFrame(list(value['averagecoordinate']))\n",
    "coordinates = pd.DataFrame(list(averagecoordinate['avg']))\n",
    "averagecoordinate = averagecoordinate.join(coordinates)\n",
    "error = pd.DataFrame(list(averagecoordinate['error']))\n",
    "errorcoordinates = pd.DataFrame(list(error['coordinates']))\n",
    "del errorcoordinates[2]\n",
    "errorcoordinates.columns = ['x_error','y_error']\n",
    "\n",
    "del averagecoordinate['avg']\n",
    "del value['averagecoordinate']\n",
    "\n",
    "# join dataframes\n",
    "frame = frame.join(value.join(averagecoordinate))\n",
    "frame = frame.join(chi2PerDof)\n",
    "frame = frame.join(probChi2)\n",
    "frame = frame.join(errorcoordinates)\n",
    "frame = frame.join(localMac)\n",
    "frame = frame.join(nMeasurements)\n",
    "del frame['regionsNodesIds']\n",
    "del frame['error']\n",
    "del frame['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = frame[frame['localMac'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = frame.sort_values(by='measurementTimestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectWindow(k):\n",
    "    start = min(df['measurementTimestamp']) + k * timestep\n",
    "    stop = start + interval\n",
    "\n",
    "    window = df[(df['measurementTimestamp'] >= start) & \n",
    "                       (df['measurementTimestamp'] < stop)]\n",
    "\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataStructures(window):\n",
    "    grids = np.zeros((len(set(window['sourceMac'])), height,width))\n",
    "\n",
    "    # dictionary of histograms (with mac addresses as keys)\n",
    "    histos = dict(zip(set(window['sourceMac']), grids))\n",
    "    \n",
    "    emptylist = [[] for i in range(len(set(window['sourceMac'])))]\n",
    "    positions = dict(zip(set(window['sourceMac']), emptylist))\n",
    "    emptylist = [[] for i in range(len(set(window['sourceMac'])))]\n",
    "    x_errors = dict(zip(set(window['sourceMac']), emptylist))\n",
    "    emptylist = [[] for i in range(len(set(window['sourceMac'])))]\n",
    "    y_errors = dict(zip(set(window['sourceMac']), emptylist))\n",
    "    \n",
    "    history = dict(zip(set(window['sourceMac']), np.zeros(len(set(window['sourceMac'])))))\n",
    "    \n",
    "    return histos, positions, x_errors, y_errors, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resetDataStructures(histos):\n",
    "    \n",
    "    histos_old = copy.deepcopy(histos)\n",
    "    \n",
    "    grids = np.zeros((len(histos), height,width))\n",
    "    histos = dict(zip(histos.keys(), grids))\n",
    "    \n",
    "    emptylist = [[] for i in range(len(histos))]\n",
    "    positions = dict(zip(histos.keys(), emptylist))\n",
    "    emptylist = [[] for i in range(len(histos))]\n",
    "    x_errors = dict(zip(histos.keys(), emptylist))\n",
    "    emptylist = [[] for i in range(len(histos))]\n",
    "    y_errors = dict(zip(histos.keys(), emptylist))\n",
    "    \n",
    "    return histos, histos_old, positions, x_errors, y_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateDataStructures(window, histos, positions, x_errors, y_errors, history):\n",
    "    for i in range(len(window)):\n",
    "        if not window['sourceMac'].values[i] in positions:\n",
    "            histos[window['sourceMac'].values[i]] = np.zeros((height,width))\n",
    "            positions[window['sourceMac'].values[i]] = []\n",
    "            x_errors[window['sourceMac'].values[i]] = []\n",
    "            y_errors[window['sourceMac'].values[i]] = []\n",
    "            history[window['sourceMac'].values[i]] = 0\n",
    "            \n",
    "        positions[window['sourceMac'].values[i]].append(window['coordinates'].values[i][:2])\n",
    "        x_errors[window['sourceMac'].values[i]].append(window['x_error'].values[i])\n",
    "        y_errors[window['sourceMac'].values[i]].append(window['y_error'].values[i])\n",
    "        \n",
    "    return histos, positions, x_errors, y_errors, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createDensityEstimates(window, gridpoints, histos, positions, x_errors, y_errors):\n",
    "\n",
    "    for mac in histos.keys():\n",
    "        if len(positions[mac]) > 0:\n",
    "            values = np.transpose(np.array(positions[mac]))\n",
    "            uncertainties = np.array([x_errors[mac], y_errors[mac]])\n",
    "            kernel = de.variable_kde(values, uncertainties)\n",
    "            binvals = kernel(gridpoints)\n",
    "            # reshape() stacks row-wise, so we use the Fortran-like index ordering\n",
    "            estimate = np.reshape(binvals, (height,width), order='F')\n",
    "            histos[mac] += estimate\n",
    "            # here we don't renormalize the evaluation grid to unity\n",
    "            '''\n",
    "            if histos[mac].sum() > 0:\n",
    "                histos[mac] /= histos[mac].sum()'''\n",
    "    return histos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memorizeNonUpdatedEstimates(histos, histos_old, positions, history, memory):\n",
    "    for mac in histos.keys():\n",
    "        if len(positions[mac]) == 0:\n",
    "            if history[mac] < memory:\n",
    "                histos[mac] += histos_old[mac]\n",
    "                history[mac] += 1\n",
    "            else:\n",
    "                history[mac] = 0\n",
    "    return histos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sumHistograms(histos):\n",
    "    # total density histogram per period\n",
    "    total_dens_histo = np.zeros((height, width))\n",
    "    \n",
    "    for mac in histos.keys():\n",
    "        total_dens_histo += histos[mac]\n",
    "                \n",
    "    return total_dens_histo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runDataAnalysis():\n",
    "    \n",
    "    for k in range(periods):\n",
    "        window = selectWindow(k)\n",
    "        if k < 1:\n",
    "            histos, positions, x_errors, y_errors, history = createDataStructures(window)\n",
    "            histos, positions, x_errors, y_errors, history =\\\n",
    "            updateDataStructures(window, histos, positions, x_errors, y_errors, history)\n",
    "            histos = createDensityEstimates(window, gridpoints, histos, positions, x_errors, y_errors)\n",
    "        else:\n",
    "            histos, histos_old, positions, x_errors, y_errors = resetDataStructures(histos)\n",
    "            histos, positions, x_errors, y_errors, history =\\\n",
    "            updateDataStructures(window, histos, positions, x_errors, y_errors, history)\n",
    "            histos = createDensityEstimates(window, gridpoints, histos, positions, x_errors, y_errors)\n",
    "            histos = memorizeNonUpdatedEstimates(histos, histos_old, positions, history, memory)\n",
    "\n",
    "        total_dens_histo = sumHistograms(histos)\n",
    "        if k == (periods - 1):\n",
    "            np.savetxt('output/scan_histo_%d_%d_%d.csv' % (memory, interval, bins**2), total_dens_histo, delimiter=',')\n",
    "            print('Output written to scan_histo_%d_%d_%d.csv' % (memory, interval, bins**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below sets up things to scan 3 parameters: \n",
    "    - memory\n",
    "    - time window interval\n",
    "    - number of evaluation grid points\n",
    "    \n",
    "We have focused on a 15 x 15 meter square area from north east coordinates (39,-39) \n",
    "to south west coordintes (54,-24).\n",
    "We divide this square by {2,3,4,...} bins to generate {4,9,16,...} evaluation grid points.\n",
    "We shift the resulting evaluation grid points to position them in the center of imaginary 'cells' or bins.\n",
    "\n",
    "The function runDataAnalysis is adapted to write only the last time window estimate to file.\n",
    "Only this last time window estimate coincides in time with the video moment.\n",
    "The start point for each run is the video moment minus the memory times the time window.\n",
    "We select a smaller dataframe 'df' which is subset of the dataframe 'frame', starting at the start point.\n",
    "The function selectWindow works on the smaller dataframe 'df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(de)\n",
    "\n",
    "memory_parameter_set = np.arange(10)\n",
    "interval_parameter_set = np.arange(10000,110000,10000) # (20000,140000,20000)\n",
    "cellsize_parameter_set = np.array([2,3,4])\n",
    "\n",
    "# 05:32:04 +2:00 UTC\n",
    "timepoint = 1436067124000\n",
    "lattice = 15\n",
    "\n",
    "for bins in cellsize_parameter_set:\n",
    "    cellsize = lattice / bins\n",
    "    height = width = bins\n",
    "    X, Y = np.mgrid[39:54:cellsize,-39:-24:cellsize]\n",
    "    X = X + cellsize/2\n",
    "    Y = Y + cellsize/2\n",
    "    # note: ravel() concatenates columns\n",
    "    gridpoints = np.vstack([X.ravel(), Y.ravel()])\n",
    "    for m in memory_parameter_set:\n",
    "        memory = m\n",
    "        for t_int in interval_parameter_set:\n",
    "            periods = m + 1\n",
    "            timestep = t_int # 30000\n",
    "            interval = t_int\n",
    "            start_time = timepoint - periods * interval\n",
    "            df = frame[frame['measurementTimestamp'] > start_time]\n",
    "            runDataAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the file paths are correct! \n",
    "\n",
    "We first read in the video count data, and bin it to make it similar to the wi-fi density estimates.\n",
    "The video count data has switched x- and y-axes, and then the y-axis need to be mirrored in the x-axis to\n",
    "make the data correspond to the wi-fi coordinate system.\n",
    "\n",
    "We assume the parameter arrays are still in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heads = np.loadtxt('/Users/philip/Documents/PhD/data-analysis/video/Sensation2015/\\\n",
    "movie1-01m12s/headcount-locations-manually.csv',delimiter=',')\n",
    "\n",
    "# first swap columns, then mirror y-coordinates in x-axis \n",
    "# to be consistent with wi-fi coordinates\n",
    "heads[:,[0, 1]] = heads[:,[1, 0]]\n",
    "heads[:,1] = -heads[:,1]\n",
    "\n",
    "corr_coeff = np.zeros((len(memory_parameter_set),len(interval_parameter_set),\\\n",
    "                       len(cellsize_parameter_set)))\n",
    "RMSE = np.zeros((len(memory_parameter_set),len(interval_parameter_set),\\\n",
    "                       len(cellsize_parameter_set)))\n",
    "\n",
    "for k in range(len(cellsize_parameter_set)):\n",
    "    bins = cellsize_parameter_set[k]\n",
    "    cellsize = lattice / bins\n",
    "    # bin head counts in two-dimensional array\n",
    "    video_estimate = np.zeros((bins, bins))\n",
    "    for b in range(len(heads)):\n",
    "        if heads[b][0] > 39 and heads[b][0] < 54 and heads[b][1] > -39 and heads[b][1] < -24:\n",
    "            x = int((heads[b][0] - 39) / cellsize)\n",
    "            y = int((heads[b][1] - (-39)) / cellsize)\n",
    "            video_estimate[y][x] += 1\n",
    "    #### now we have video_estimate in the same format as the wifi_estimate to be loaded\n",
    "    for i in range(len(memory_parameter_set)):\n",
    "        m = memory_parameter_set[i]\n",
    "        for j in range(len(interval_parameter_set)):\n",
    "            t_int = interval_parameter_set[j]\n",
    "            wifi_estimate = np.loadtxt('/Users/philip/PycharmProjects/DensityEstimation/'\n",
    "            'output/scan_histo_%d_%d_%d.csv' % (m, t_int, bins**2), delimiter=',')\n",
    "            # now look at the correlation coefficient between the two distributions\n",
    "            X = video_estimate.ravel()\n",
    "            Y = wifi_estimate.ravel()\n",
    "            corr_coeff[i,j,k] = pearsonr(X, Y)[0]\n",
    "            RMSE[i,j,k] = abs(X.sum() - Y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_coeff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_coeff.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "fig = plt.figure(figsize=(16,12))\n",
    "for i in range(corr_coeff.shape[2]):\n",
    "    ax = fig.add_subplot(2,2,i+1, projection='3d')\n",
    "    a = interval_parameter_set/1000\n",
    "    b = memory_parameter_set\n",
    "    x_data, y_data = np.meshgrid(a,b)\n",
    "    zs = corr_coeff[:,:,i].ravel()\n",
    "    z_data = zs.reshape(x_data.shape)\n",
    "    ax.plot_surface(x_data, y_data, z_data, rstride=1, cstride=1, linewidth=1, antialiased=False, alpha=0.5)\n",
    "    plt.xlabel('Time window [s]')\n",
    "    plt.ylabel('Memory')\n",
    "    ax.set_zlabel('pearson r')\n",
    "    plt.title('Lattice %dx%d' % (cellsize_parameter_set[i],cellsize_parameter_set[i]))\n",
    "#plt.savefig('/Users/philip/Documents/PhD/data-analysis/video/Sensation2015/movie1-01m12s/param-scan-03-3dsurf.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,12))\n",
    "for i in range(RMSE.shape[2]):\n",
    "    ax = fig.add_subplot(2,2,i+1, projection='3d')\n",
    "    a = interval_parameter_set/1000\n",
    "    b = memory_parameter_set\n",
    "    x_data, y_data = np.meshgrid(a,b)\n",
    "    zs = RMSE[:,:,i].ravel()\n",
    "    z_data = zs.reshape(x_data.shape)\n",
    "    ax.plot_surface(x_data, y_data, z_data, rstride=1, cstride=1, linewidth=1, antialiased=False, alpha=0.5)\n",
    "    plt.xlabel('Time window [s]')\n",
    "    plt.ylabel('Memory')\n",
    "    ax.set_zlabel('RMSE')\n",
    "    plt.title('Lattice %dx%d' % (cellsize_parameter_set[i],cellsize_parameter_set[i]))\n",
    "#plt.savefig('/Users/philip/Documents/PhD/data-analysis/video/Sensation2015/movie1-01m12s/param-scan-03-rmse.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print('Lattice size:', cellsize_parameter_set[i]**2, '; max pearson:', corr_coeff[:,:,i].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_index = np.unravel_index(np.argmax(corr_coeff), corr_coeff.shape)\n",
    "print('Optimal parameters:','\\n',\n",
    "      'Lattice size:', '%dx%d' % (cellsize_parameter_set[max_index[2]],cellsize_parameter_set[max_index[2]]),'\\n',\n",
    "      'Memory:', memory_parameter_set[max_index[0]],'\\n',\n",
    "      'Time window (s):', interval_parameter_set[max_index[1]]/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_coeff[8,9,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_coeff[8,9,2]==corr_coeff[:,:,2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create scatter plot of estimates with max correlation coefficient\n",
    "# re-create video estimate histo\n",
    "bins = cellsize_parameter_set[2] # max_index[2]\n",
    "cellsize = lattice / bins\n",
    "# bin head counts in two-dimensional array\n",
    "video_estimate = np.zeros((bins, bins))\n",
    "for b in range(len(heads)):\n",
    "    if heads[b][0] > 39 and heads[b][0] < 54 and heads[b][1] > -39 and heads[b][1] < -24:\n",
    "        x = int((heads[b][0] - 39) / cellsize)\n",
    "        y = int((heads[b][1] - (-39)) / cellsize)\n",
    "        video_estimate[y][x] += 1\n",
    "# re-create wi-fi estimate histo\n",
    "m = memory_parameter_set[max_index[0]] # max_index[0]\n",
    "t_int = interval_parameter_set[max_index[1]] # max_index[1]\n",
    "wifi_estimate = np.loadtxt('/Users/philip/PycharmProjects/DensityEstimation/'\n",
    "'output/scan_histo_%d_%d_%d.csv' % (m, t_int, bins**2), delimiter=',')\n",
    "# now look at the correlation coefficient between the two distributions\n",
    "X = video_estimate.ravel()\n",
    "Y = wifi_estimate.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,4)) # \n",
    "\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(X,Y,'ro')\n",
    "plt.xlim([X.min()-1,X.max()+1])\n",
    "plt.ylim([Y.min()-50,Y.max() + 50])\n",
    "plt.xlabel('Video estimates')\n",
    "plt.ylabel('Wi-Fi estimates')\n",
    "plt.title('2x2 lattice (r = ...)')\n",
    "#plt.savefig('/Users/philip/Documents/PhD/data-analysis/video/Sensation2015/movie1-01m12s/scatter-plot-01a.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
